---
title: "R Notebook - IRIS Data"
output: html_notebook
---
 

```{r}
library(tidyverse)
install.packages("caret")
install.packages("ggvis")
install.packages("gmodels")
train = read_csv("iris.csv.txt")
summary(iris)
iris  = na.omit(iris)
plot(iris, col = iris$Species)
legend(7,4,3,unique(iris$Species),col=1:length(iris$Species),pch = 1)
```

```{r}
hist(iris$Sepal.Length)
library(ggvis)
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points()

```
The first graph shows that there is a high correlation between the sepal length and sepal width of a Setosa flower. The second graph shows a high correlation when all the species are considered together rather than individually.

```{r}
cor(iris$Petal.Length, iris$Petal.Width)
x=levels(iris$Species)
print(x[1])
cor(iris[iris$Species == x[1],1:4])
print(x[2])
cor(iris[iris$Species == x[2],1:4])
print(x[3])
cor(iris[iris$Species == x[3],1:4])

```

```{r}
plot(iris$Species)
```
The preview shows the 3 classes being equally distributed. Now, the next step is to normalize the values in different columns in the dataset.
```{r}
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}

# Normalize the `iris` data
iris_norm <-as.data.frame(lapply(iris[1:4], normalize))

# Summarize `iris_norm`
summary(iris_norm)
```

Now, to construct good training and test sets, one has to randomly shuffle the dataset and divide them into train and test. 


```{r}
set.seed(1234)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.67, 0.33))
iris.training <-iris[ind==1, 1:4]
iris.test <- iris[ind==2,1:4]
head(iris.training)
head(iris.test)
iris.trainLabels <- iris[ind==1,5]
iris.testLabels <- iris[ind==2, 5]
library(class)
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)

```

Now, we can evaluate the model performance using gmodels library in R 

```{r}

library(gmodels)
print(CrossTable(x = iris.testLabels, y=iris_pred, prop.chisq = TRUE))


```
Can also use the caret package for common machine learning problems 


```{r}
library(caret)
index <- createDataPartition(iris$Species, p=0.75, list=FALSE)
iris.training <- iris[index,]
iris.test <- iris[-index,]
names(getModelInfo())
model_knn <- train(iris.training[, 1:4], iris.training[, 5], method='knn')
predictions<-predict(object=model_knn,iris.test[,1:4])
table(predictions)

# Confusion matrix 

confusionMatrix(predictions,iris.test[,5])



```
